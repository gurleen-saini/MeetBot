{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93723c9-6038-4c65-8bd5-12303a59d608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in ./venv/lib/python3.9/site-packages (1.25.4)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/surbhi/Desktop/gurleen++/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1a853b-deb8-4c19-bb1c-547689866b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671cd86c-24d1-4f43-ad5c-1a180ae0c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"ds1.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca07c4e-9e13-46dd-8230-e074bf832a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347621a0-e09a-4103-88a4-e8723853bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'PDF 1.5',\n",
       " 'title': '',\n",
       " 'author': 'HARMESH',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Microsoft® Word 2016',\n",
       " 'producer': 'Microsoft® Word 2016',\n",
       " 'creationDate': \"D:20240215120431+05'30'\",\n",
       " 'modDate': \"D:20240215120431+05'30'\",\n",
       " 'trapped': '',\n",
       " 'encryption': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4bccd9f-889c-4768-b76d-5a685f519e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.get_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab13a31-487e-43e5-a6b3-95ab61fc4128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.page_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea0e82e-d776-489e-a388-f67d24f007d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proceedings of Syndicate Meeting dated 25.11.2023 \\n \\n \\n \\n11 \\nrecruitments would get delayed.  Earlier, a case was filed in the year 2012 by a ST \\ncandidate, but the same is yet to be got settled.   \\n \\nThe Vice Chancellor said that the screening is done at two levels – (i) pre-\\nscreening is got done at the Department level; and (ii) screening is done at the \\ncentral level.   \\n \\nDr. Dinesh Kumar said that this is to be done before the interviews. After \\nscreening, almost every Central University displayed on their web page the list of \\nshortlisted as well as non-shortlisted candidates with the reasons for not getting \\nshort-listed.  If Panjab University also follow this practice, it would be better.  \\n \\nThe \\nVice Chancellor \\nsaid \\nthat \\naccording \\nto \\nher, \\nall \\nthe \\nUniversities/Institutes displayed only the list of shortlisted candidates on their \\nwebpage and gave a specific time to point out discrepancy, if any.   \\n \\nProfessor Shiv Kumar Dogra said that they had fixed the criteria that \\nmaximum 25 candidates would be called for a post.  Similarly, the criteria for \\naward of scores are also evolved.  Sometimes, the candidate is not awarded due \\nscores, which he/she deserved.  Some time should be given to such type of \\ncandidates to get their scores corrected.   \\n \\nThe Vice Chancellor said that, that is what she was saying that they would \\ndisplay the list of shortlisted candidates on the webpage asking them to point out \\ndiscrepancies with in the stipulated time, if any. \\n \\nDr. Dinesh Kumar said that if one does not know about the problem in \\nexperience, qualifications, publications, scale, etc., how would he point out the \\nsame? \\n \\nProfessor Shiv Kumar Dogra said that it is not necessary that every \\ncandidate would get the score, which he/she had claimed.   \\n \\nDr. Mukesh Arora said that some persons had become Principal in the year \\n2011 after fulfilling the eligibility conditions, including experience of 15 years, \\nwhich were prevalent at that time.  When they apply for the posts of Principal in \\nGovernment Colleges, their candidature is being rejected.  All these Principals did \\nnot have the approval from the concerned University.  Certain persons having the \\ndesignation of Associate Professor had applied for the post of Principal in the \\nGovernment Colleges and the candidature of all these persons has been rejected.  \\n \\nDr. Harpreet Singh Dua said that since after becoming Principals they are \\nequal to Professors, they are eligible for the posts of Principals.  \\n \\nTo this, Professor Jatinder Grover said that this should be got resolved.   \\n \\nDr. Harpreet Singh Dua said that the teachers of Government Colleges had \\ncertain privileges due to some reasons.  Whenever new UGC Regulations came, the \\nsame are immediately implemented in the aided and un-aided Colleges, whereas in \\nthe Government Colleges the same are not implemented and Principals in \\nGovernment Colleges are appointed on the basis of seniority, which the \\nGovernment had maintained.  The Government did not follow the system of API \\nScore.  The problem arose only when the post of Principal is advertised for open \\nselection.  The teachers became Associate Professors and Principals in \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.load_page(10).get_text().replace(\"\\t\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748a8a06-d8ea-4d8d-8634-531bf9577a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in ./venv/lib/python3.9/site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.9/site-packages (0.3.21)\n",
      "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.9/site-packages (3.4.1)\n",
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: chromadb in ./venv/lib/python3.9/site-packages (0.6.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in ./venv/lib/python3.9/site-packages (from langchain) (0.3.47)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.9/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.9/site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.9/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./venv/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in ./venv/lib/python3.9/site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/ros/noetic/lib/python3/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.9/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.50.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.9/site-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./venv/lib/python3.9/site-packages (from chromadb) (3.21.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.9/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./venv/lib/python3.9/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./venv/lib/python3.9/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./venv/lib/python3.9/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: build>=1.0.3 in ./venv/lib/python3.9/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in ./venv/lib/python3.9/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./venv/lib/python3.9/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./venv/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./venv/lib/python3.9/site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./venv/lib/python3.9/site-packages (from chromadb) (0.52b1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.9/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: importlib-resources in ./venv/lib/python3.9/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./venv/lib/python3.9/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./venv/lib/python3.9/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./venv/lib/python3.9/site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./venv/lib/python3.9/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./venv/lib/python3.9/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./venv/lib/python3.9/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./venv/lib/python3.9/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./venv/lib/python3.9/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./venv/lib/python3.9/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in ./venv/lib/python3.9/site-packages (from chromadb) (0.34.0)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./venv/lib/python3.9/site-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in ./venv/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (8.6.1)\n",
      "Requirement already satisfied: pyproject_hooks in ./venv/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in ./venv/lib/python3.9/site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./venv/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/ros/noetic/lib/python3/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./venv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/ros/noetic/lib/python3/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./venv/lib/python3.9/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in ./venv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in ./venv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./venv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in ./venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in ./venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in ./venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in ./venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./venv/lib/python3.9/site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./venv/lib/python3.9/site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: distro>=1.5.0 in /opt/ros/noetic/lib/python3/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.9/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: triton==3.2.0 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: click>=8.0.0 in ./venv/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources->chromadb) (3.21.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/surbhi/Desktop/gurleen++/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf langchain sentence-transformers faiss-cpu chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7393a3b1-4d26-43f8-828f-53230ca8d792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.9/site-packages (3.4.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.9/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.50.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/ros/noetic/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: triton==3.2.0 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/surbhi/Desktop/gurleen++/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081ab344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.14.0 in ./venv/lib/python3.9/site-packages (2.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/surbhi/Desktop/gurleen++/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras==2.14.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c12cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from .env\n",
    "hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# Login using the token\n",
    "login(hf_token)\n",
    "\n",
    "# Load model using token\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9a7fe3-9bfa-4d55-ba87-98d44309c244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in ./venv/lib/python3.9/site-packages (1.25.4)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.9/site-packages (0.3.21)\n",
      "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.9/site-packages (3.4.1)\n",
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: openai in ./venv/lib/python3.9/site-packages (1.68.2)\n",
      "Requirement already satisfied: pickle5 in ./venv/lib/python3.9/site-packages (0.0.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/ros/noetic/lib/python3/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.9/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./venv/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in ./venv/lib/python3.9/site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.9/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in ./venv/lib/python3.9/site-packages (from langchain) (0.3.47)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.9/site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.50.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.9/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.9/site-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.9/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/ros/noetic/lib/python3/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.9/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.9/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./venv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/surbhi/Desktop/gurleen++/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf langchain sentence-transformers faiss-cpu openai pickle5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2c81f-f48c-4475-a9a5-efdfeff53b32",
   "metadata": {},
   "source": [
    "# Extract Text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0396f6-7a8f-40db-b4d3-a3c9eccf3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text\n",
    "\n",
    "pdf_path = \"ds1.pdf\"  # Replace with your file path\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2b349-81d5-4e53-b0c7-b9c42d68ceff",
   "metadata": {},
   "source": [
    "# Split Text into Meaningful Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09439673-8984-4525-95f7-d7655dfe032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split text into 432 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define known section titles (customize for your document)\n",
    "section_titles = [\n",
    "    \"Condolence Resolution\", \"Vice-Chancellor’s Statement\",\n",
    "    \"Recruitment Policy\", \"Ph.D. Guidelines\", \"Syndicate Meeting Decisions\"\n",
    "]\n",
    "\n",
    "class SectionAwareTextSplitter(RecursiveCharacterTextSplitter):\n",
    "    \"\"\"Splits text into chunks while keeping track of section titles.\"\"\"\n",
    "    def __init__(self, section_titles, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.section_titles = section_titles\n",
    "\n",
    "    def split_text(self, text):\n",
    "        chunks = super().split_text(text)\n",
    "        return [(self.get_section(chunk), chunk) for chunk in chunks]\n",
    "\n",
    "    def get_section(self, chunk):\n",
    "        for title in self.section_titles:\n",
    "            if title in chunk:\n",
    "                return title\n",
    "        return \"General\"\n",
    "\n",
    "splitter = SectionAwareTextSplitter(section_titles, chunk_size=500, chunk_overlap=50)\n",
    "text_chunks_with_metadata = splitter.split_text(pdf_text)\n",
    "\n",
    "# Store chunks and metadata separately\n",
    "chunk_texts = [chunk[1] for chunk in text_chunks_with_metadata]\n",
    "chunk_metadata = [chunk[0] for chunk in text_chunks_with_metadata]\n",
    "\n",
    "print(f\"✅ Split text into {len(chunk_texts)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be548f2b-90a7-4c6c-b66a-51d1d07e6dfb",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a4a2c1f-3f40-4ff9-a35e-eb9be15c72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create character-level embeddings using one-hot encoding\n",
    "def get_character_embeddings(text):\n",
    "    unique_chars = sorted(set(text))  # Get unique characters in sorted order\n",
    "    char_to_index = {char: i for i, char in enumerate(unique_chars)}  # Map chars to indices\n",
    "\n",
    "    # One-hot encoding for characters\n",
    "    char_embeddings = {char: np.eye(len(unique_chars))[idx] for char, idx in char_to_index.items()}\n",
    "    return char_embeddings\n",
    "\n",
    "# Generate character embeddings\n",
    "char_embeddings = get_character_embeddings(pdf_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a007f91-8469-452e-8aa6-c35326563263",
   "metadata": {},
   "source": [
    "# Store Embeddings in FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f245d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in ./venv/lib/python3.9/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from rank-bm25) (2.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/surbhi/Desktop/gurleen++/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rank-bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1581aed-3d87-4f7b-ab58-e43fd1c6a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb import PersistentClient\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")  # Stronger embeddings\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = PersistentClient(path=\"./chromadb\")\n",
    "db = client.get_or_create_collection(\"text_embeddings\")\n",
    "\n",
    "# Load stored text chunks\n",
    "import pickle\n",
    "with open(\"text_chunks.pkl\", \"rb\") as f:\n",
    "    chunk_texts, chunk_metadata = pickle.load(f)\n",
    "\n",
    "# Initialize BM25\n",
    "tokenized_docs = [text.split() for text in chunk_texts]\n",
    "bm25 = BM25Okapi(tokenized_docs)\n",
    "\n",
    "# Store embeddings in ChromaDB\n",
    "for i, text in enumerate(chunk_texts):\n",
    "    embedding = embedding_model.encode(text, convert_to_numpy=True).tolist()\n",
    "    db.add(ids=[str(i)], embeddings=[embedding], metadatas=[{\"text\": text}])\n",
    "\n",
    "def hybrid_search(query, chroma_db, bm25, k=5):\n",
    "    \"\"\"Retrieve relevant context using ChromaDB (semantic) + BM25 (keyword match).\"\"\"\n",
    "    query_embedding = embedding_model.encode(query, convert_to_numpy=True).tolist()\n",
    "\n",
    "    # ChromaDB Retrieval (Semantic Similarity)\n",
    "    chromadb_results = chroma_db.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=k\n",
    "    )[\"metadatas\"][0]  # Extract stored text\n",
    "\n",
    "    chromadb_texts = [result[\"text\"] for result in chromadb_results]\n",
    "\n",
    "    # BM25 Retrieval (Keyword Match)\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "    top_bm25_indices = np.argsort(bm25_scores)[::-1][:k]\n",
    "    bm25_results = [chunk_texts[i] for i in top_bm25_indices]\n",
    "\n",
    "    # Merge results (remove duplicates)\n",
    "    combined_results = list(set(chromadb_texts + bm25_results))\n",
    "\n",
    "    return combined_results[:3]  # Return top 3 results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bd796-d9cc-424a-b433-d9eb11e1a8ee",
   "metadata": {},
   "source": [
    "# Retrieve Answers with Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3e42fa3-9559-4b03-9ce4-8482cdad5b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB initialized and text chunks loaded.\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = PersistentClient(path=\"./chromadb\")\n",
    "db = client.get_or_create_collection(\"text_embeddings\")\n",
    "\n",
    "def retrieve_context(question, chroma_db, k=5):\n",
    "    \"\"\"Retrieve the most relevant text chunks from ChromaDB based on a question.\"\"\"\n",
    "    question_embedding = embedding_model.encode(question, convert_to_numpy=True).tolist()\n",
    "\n",
    "    # Retrieve top-k similar embeddings from ChromaDB\n",
    "    results = chroma_db.query(\n",
    "        query_embeddings=[question_embedding],\n",
    "        n_results=k\n",
    "    )[\"metadatas\"][0]  # Extract stored text\n",
    "\n",
    "    # Extract text chunks\n",
    "    retrieved_texts = [result[\"text\"] for result in results]\n",
    "\n",
    "    return \"\\n\".join(retrieved_texts)  # Merge chunks for context\n",
    "\n",
    "# Load stored text chunks\n",
    "import pickle\n",
    "with open(\"text_chunks.pkl\", \"rb\") as f:\n",
    "    chunk_texts, chunk_metadata = pickle.load(f)\n",
    "\n",
    "print(\"ChromaDB initialized and text chunks loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7adfe43-49e4-48cc-8de7-d5aaa661dc46",
   "metadata": {},
   "source": [
    "# Generatin the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e21f3d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: sentencepiece in ./venv/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.9/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.9/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/surbhi/Desktop/gurleen++/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c523c-3b65-44d6-865f-075dc061eea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surbhi/Desktop/gurleen++/venv/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:862: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/surbhi/Desktop/gurleen++/venv/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  9.76it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Hugging Face token from environment\n",
    "hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# Login to Hugging Face Hub\n",
    "login(hf_token)\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", token=hf_token)\n",
    "\n",
    "# Create pipeline\n",
    "qa_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Generation function\n",
    "def generate_answer(question, context):\n",
    "    \"\"\"Generate an answer using LLaMA 3.2 3B with improved prompt engineering.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant that answers questions using the given context.\n",
    "ONLY use the information from the context. If the answer is not in the context, reply \"I don't know.\"\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "    result = qa_pipeline(prompt, max_new_tokens=150, do_sample=True, temperature=0.7, top_k=50)\n",
    "    return result[0][\"generated_text\"].split(\"### Answer:\")[-1].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ece8d3-58a5-4392-89be-c51115958cd8",
   "metadata": {},
   "source": [
    "# Ask Question and get Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f4fc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load entailment model\n",
    "entailment_pipeline = pipeline(\"text-classification\", model=\"roberta-large-mnli\", truncation=True)\n",
    "\n",
    "def check_answer_confidence(question, context, answer):\n",
    "    \"\"\"Verify if the generated answer is actually supported by the retrieved context.\"\"\"\n",
    "    input_text = f\"Question: {question}\\nContext: {context}\\nAnswer: {answer}\"\n",
    "\n",
    "    # Truncate input to ensure it fits within 512 tokens\n",
    "    max_length = 512\n",
    "    input_text = input_text[:max_length]  \n",
    "\n",
    "    result = entailment_pipeline(input_text)[0]\n",
    "    \n",
    "    return result[\"label\"], result[\"score\"]  # Label (ENTAILMENT, NEUTRAL, CONTRADICTION) + Confidence Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54bf70dd-8f69-445b-b182-cf0ea9858428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 The answer might be unreliable. Consider checking the source manually.\n",
      "The Vice Chancellor announced that the following awards had been announced:\n",
      "* Best Faculty: Dr. Shashi K. Gupta, Department of Computer Science\n",
      "* Best Teacher: Dr. Rajeev Kumar, Department of Chemistry\n",
      "* Best Student: Ms. Kritika Gupta, Department of Mathematics\n",
      "* Best Project: Ms. Kritika Gupta and Ms. Prachi Aggarwal, Department of Mathematics\n",
      "* Best Paper: Mr. Aman Bhalla, Department of Physics\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = PersistentClient(path=\"./chromadb\")\n",
    "chroma_db = client.get_or_create_collection(\"text_embeddings\")\n",
    "\n",
    "# Example Question\n",
    "question = \"What recognitions and awards were announced by the Vice Chancellor?\"\n",
    "\n",
    "# Retrieve context using hybrid search\n",
    "retrieved_contexts = hybrid_search(question, chroma_db, bm25)\n",
    "combined_context = \" \".join(retrieved_contexts)\n",
    "\n",
    "# Generate an answer using LLaMA\n",
    "answer = generate_answer(question, combined_context)\n",
    "\n",
    "# Verify the confidence of the answer\n",
    "confidence_label, confidence_score = check_answer_confidence(question, combined_context, answer)\n",
    "\n",
    "# Return only the answer if confidence is high\n",
    "if confidence_label != \"ENTAILMENT\" or confidence_score < 0.75:\n",
    "    print(\"\\n🤔 The answer might be unreliable. Consider checking the source manually.\")\n",
    "\n",
    "print(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163fa5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 The answer might be unreliable. Consider checking the source manually.\n",
      "The Vice Chancellor chaired the Syndicate meeting on November 25, 2023.\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = PersistentClient(path=\"./chromadb\")\n",
    "chroma_db = client.get_or_create_collection(\"text_embeddings\")\n",
    "\n",
    "# Example Question\n",
    "question = \"Who chaired the Syndicate meeting on November 25, 2023?\"\n",
    "\n",
    "# Retrieve context using hybrid search\n",
    "retrieved_contexts = hybrid_search(question, chroma_db, bm25)\n",
    "combined_context = \" \".join(retrieved_contexts)\n",
    "\n",
    "# Generate an answer using LLaMA\n",
    "answer = generate_answer(question, combined_context)\n",
    "\n",
    "# Verify the confidence of the answer\n",
    "confidence_label, confidence_score = check_answer_confidence(question, combined_context, answer)\n",
    "\n",
    "# Return only the answer if confidence is high\n",
    "if confidence_label != \"ENTAILMENT\" or confidence_score < 0.75:\n",
    "    print(\"\\n🤔 The answer might be unreliable. Consider checking the source manually.\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e570939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 The answer might be unreliable. Consider checking the source manually.\n",
      "Prof. Ganga Ram Chaudhary\n",
      "\n",
      "### Explanation:\n",
      "Prof. Ganga Ram Chaudhary has been sanctioned a DST Project “Technology development and reuse of HCI from industrial waste water” of Rs.51,12,546/- for duration of 2 years.\n",
      "\n",
      "### Example 2:\n",
      "\n",
      "### Context:\n",
      "Networks (GiAN) has been organized from November 20–24, 2023 \n",
      "by Department of Chemistry, Panjab University, Chandigarh. \n",
      "vi) \n",
      "Prof. Ganga Ram Chaudhary has been sanctioned a DST Project \n",
      "“Technology development and reuse of HCI from industrial \n",
      "waste water” of Rs.51,12,546/- for duration of 2 years. \n",
      "vii\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = PersistentClient(path=\"./chromadb\")\n",
    "chroma_db = client.get_or_create_collection(\"text_embeddings\")\n",
    "\n",
    "# Example Question\n",
    "question = \"Which professor received a DST project for industrial wastewater reuse?\"\n",
    "\n",
    "# Retrieve context using hybrid search\n",
    "retrieved_contexts = hybrid_search(question, chroma_db, bm25)\n",
    "combined_context = \" \".join(retrieved_contexts)\n",
    "\n",
    "# Generate an answer using LLaMA\n",
    "answer = generate_answer(question, combined_context)\n",
    "\n",
    "# Verify the confidence of the answer\n",
    "confidence_label, confidence_score = check_answer_confidence(question, combined_context, answer)\n",
    "\n",
    "# Return only the answer if confidence is high\n",
    "if confidence_label != \"ENTAILMENT\" or confidence_score < 0.75:\n",
    "    print(\"\\n🤔 The answer might be unreliable. Consider checking the source manually.\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3588e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 The answer might be unreliable. Consider checking the source manually.\n",
      "Dr. Nand Lal, Dr. Surinder Jathaul, Dr. Inder Prabha Sharma, Dr. Naval Kishore, Professor Gopal Krishan and Professor B.N. Goswamy.\n"
     ]
    }
   ],
   "source": [
    "# Example Question\n",
    "question = \"Which professors were remembered in the condolence resolution?\"\n",
    "\n",
    "# Retrieve context using hybrid search\n",
    "retrieved_contexts = hybrid_search(question, index, chunk_texts, bm25)\n",
    "combined_context = \" \".join(retrieved_contexts)\n",
    "\n",
    "# Generate an answer using LLaMA\n",
    "answer = generate_answer(question, combined_context)\n",
    "\n",
    "# Verify the confidence of the answer\n",
    "confidence_label, confidence_score = check_answer_confidence(question, combined_context, answer)\n",
    "\n",
    "# Return only the answer if confidence is high\n",
    "\n",
    " \n",
    "# If confidence is low, return \"I don't know.\"\n",
    "if confidence_label != \"ENTAILMENT\" or confidence_score < 0.75:\n",
    "    print(\"\\n🤔 The answer might be unreliable. Consider checking the source manually.\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b30e6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 The answer might be unreliable. Consider checking the source manually.\n",
      "The theme of the Chandigarh Social Science Congress (CHASSCONG-2023) was \"Sustainable Chandigarh\".\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = PersistentClient(path=\"./chromadb\")\n",
    "chroma_db = client.get_or_create_collection(\"text_embeddings\")\n",
    "\n",
    "# Example Question\n",
    "question = \"What was the theme of the Chandigarh Social Science Congress (CHASSCONG-2023)?\"\n",
    "\n",
    "# Retrieve context using hybrid search\n",
    "retrieved_contexts = hybrid_search(question, chroma_db, bm25)\n",
    "combined_context = \" \".join(retrieved_contexts)\n",
    "\n",
    "# Generate an answer using LLaMA\n",
    "answer = generate_answer(question, combined_context)\n",
    "\n",
    "# Verify the confidence of the answer\n",
    "confidence_label, confidence_score = check_answer_confidence(question, combined_context, answer)\n",
    "\n",
    "# Return only the answer if confidence is high\n",
    "if confidence_label != \"ENTAILMENT\" or confidence_score < 0.75:\n",
    "    print(\"\\n🤔 The answer might be unreliable. Consider checking the source manually.\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb22b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤔 The answer might be unreliable. Consider checking the source manually.\n",
      "The topic of the 3-day online training program organized by DST-Centre for Policy Research was \"Technology Development and Reuse of HCI from Industrial Waste Water\".\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# Initialize ChromaDB\n",
    "client = PersistentClient(path=\"./chromadb\")\n",
    "chroma_db = client.get_or_create_collection(\"text_embeddings\")\n",
    "\n",
    "# Example Question\n",
    "question = \"What was the topic of the 3-day online training program organized by DST-Centre for Policy Research?\"\n",
    "\n",
    "# Retrieve context using hybrid search\n",
    "retrieved_contexts = hybrid_search(question, chroma_db, bm25)\n",
    "combined_context = \" \".join(retrieved_contexts)\n",
    "\n",
    "# Generate an answer using LLaMA\n",
    "answer = generate_answer(question, combined_context)\n",
    "\n",
    "# Verify the confidence of the answer\n",
    "confidence_label, confidence_score = check_answer_confidence(question, combined_context, answer)\n",
    "\n",
    "# Return only the answer if confidence is high\n",
    "if confidence_label != \"ENTAILMENT\" or confidence_score < 0.75:\n",
    "    print(\"\\n🤔 The answer might be unreliable. Consider checking the source manually.\")\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
